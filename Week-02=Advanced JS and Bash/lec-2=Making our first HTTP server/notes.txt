In this lecture we are going to learn about Node.js and HTTP servers(HyperText Transfer Protocol)(a Protocol for frontend to interact with backend)
First let's start with the basics.
What is ECMAscript. ECMAscript is a scripting language specification on which JavaScript is based. A specification is like a documentation. ECMAscript tells us what JavaScript should look like and its syntax.
ECMAscript serves as the guidelines or rules for scripting languages design. While on the other hand JavaScript is the implementation. JavaScript is the scripting language that conforms to ECMAscript specification, and is its most widely used implementation.
JavaScript also includes additional features like DOM manipulation which is crucial for web development but is not defined by ECMAscript but are provided by browsers and NodeJS.
Common JS browser engines are V8 and SpiderMonkey.
IMPORTANT INTERVIEW QUESTION!!! What is NodeJS, is it a Programming language? What is it used for? Why is it used?
Node.js is not a programming language, but rather an environment that allows JavaScript to be executed outside of a web browser. It is built on the V8 JavaScript engine, which is developed by Google. Node.js is used for various purposes, including web server development, real-time applications, and RESTful APIs.
The reason Node.js is used is due to its non-blocking, event-driven architecture. This allows it to handle a large number of simultaneous connections efficiently, making it suitable for applications that require high concurrency. Additionally, Node.js has a large and active community, which contributes to its extensive library ecosystem.
Because of development of Node.js JavaScript became a popular backend language as earlier it was only used in frontend.
What is Bun? Other than the fact that JS is a single threaded language, Node.js is slow(multiple reasons for it), so some smart people said they wanted to re-write the JS runtime for backend and introduced Bun, which has a significantly faster run-time, and it is written in Zig. 
Now let us learn what all we can do with Node.js-
1. Create clis(command line interface)
2. Create a video player
3. Create games
4. Create an HTTP server(most popular usecase of Node.js)
What is an HTTP server?
It stands for HyperText Transfer Protocol, it is a protocol that is defined for machines to communicate, and specifically for websites, it is the most common way for your website's frontend to talk to its backend.
There are many protocols, example a popular one is Web RTC protocol, but we will learn about protocols later.
Backend talking to frontend and vice versa is not at all as easy as it sounds because there are huge networks of optical fibres running under the sea that help us connect the world.
HTTP server is any server(any code) that follows HTTP protocol.
Protocols are a set of rules and conventions that define how data is transmitted and communicated over a network. They are essential for enabling communication between devices and systems, ensuring that data is exchanged in a standardized and organized manner. Protocols govern various aspects of communication, including the format of data, error handling, and the sequence of actions performed during communication.
Protocols are used to establish a common ground for communication between different devices, applications, or systems, allowing them to understand and interpret the information being exchanged. Without protocols, it would be challenging for devices from different manufacturers or software from different developers to communicate effectively.
HTTP (Hypertext Transfer Protocol) is one of the fundamental protocols used on the internet. It defines how messages are formatted and transmitted, as well as how web servers and browsers should respond to various commands. HTTP is the foundation of data communication on the World Wide Web, enabling the transfer of hypertext (linked documents) between web servers and browsers.
Key features of HTTP include:
Statelessness: Each request from a client to a server is independent and contains all the information needed for the server to fulfill the request. The server does not retain information about previous requests.
Connectionless: Each request and response in the HTTP protocol is independent, and there is no continuous connection between the client and the server. After a response is sent, the connection is closed.
Text-based: HTTP messages are typically text-based, making them human-readable and easy to understand. The information is usually transmitted in the form of headers and a message body.
Request-Response Model: HTTP follows a simple request-response model. A client (e.g., a web browser) sends a request to a server, and the server responds with the requested information or an error message.
HTTP(client side) consists of-
Protocol(HTTP/HTTPS), the protocol decides what kind of request is being sent back to the server which then returns the request with the required data rendered by browser as the frontend of the website or any other query requested by user.
Address(URL/IP/PORT), this represents the address of the backend server of website
Route
Headers, Body, query params
Method
HTTP(server side) consists of-
Response headers
response body
Status codes
Every URL consists of first the name of protocol, then the URL, then the route
Example - http://www.google.com/search?q=node.js
Here 'http' is the protocol and '/search' is the route(defines what the website has to do) and 'q=node.js' is the query param
Header- Cookie- 123as@rjg/E223
Body- What is 2 + 2(usually in JSON)
Method: POST
You can see all this by inspecting any website you see on internet
Just go to inspect, then Network, then see in headers for headers and payload for body.
Now let us take a deep dive into HTTP protocol and see what really happens when we fire the HTTP request-
1. Browser parses the URL
2. Does a DNS lookup(converts google.com to an IP)
3. Establishes a connection to the IP(does handshake(OSI model computer network concept))
What is DNS resolution?
URLs are just like contacts in your phone.
In the end, they map to an IP
If you ever buy a URL of your own, you will need to point it to the IP of your server.(Domain Name Server Resolution)
In JavaScript, there is no inherent concept of an API (Application Programming Interface) in the way that it exists as a specific language feature. However, JavaScript is a versatile language that can be used on both the client and server sides, and APIs are commonly implemented in JavaScript for communication between different software components.
Here's a breakdown of the topic:
API Definition:
An API is a set of rules and protocols that allows one piece of software application to interact with another. It defines the methods and data formats that applications can use to request and exchange information. APIs can be implemented in various ways, and HTTP is one common protocol used for communication.
JavaScript and APIs:
On the client-side, JavaScript often interacts with APIs provided by servers. These are commonly known as HTTP APIs or Web APIs. These APIs expose endpoints (URLs) that can be accessed using HTTP methods (such as GET, POST, etc.), and they return data, often in JSON format.
JavaScript can make HTTP requests to these APIs using technologies like the XMLHttpRequest object or the more modern Fetch API. Additionally, JavaScript frameworks like Axios or libraries like jQuery provide convenient methods for making HTTP requests.
Server-side JavaScript and APIs:
With the advent of technologies like Node.js, JavaScript can also be used on the server-side. This means you can build server-side APIs using JavaScript. Express.js is a popular framework for building server-side applications, including APIs.
RESTful APIs:
REST (Representational State Transfer) is a common architectural style for designing networked applications. RESTful APIs use HTTP methods and follow certain conventions for structuring URLs. JavaScript is frequently used to consume and interact with RESTful APIs.
GraphQL:
GraphQL is another API technology that allows clients to request only the data they need. It is an alternative to RESTful APIs and is becoming increasingly popular. JavaScript can be used to consume GraphQL APIs.
NOTE: Using PORT we can host multiple servers on one single device by assigning different port numbers to different servers.
URL parsing is a function of traffic management and load-balancing products that scan URLs to determine how to forward traffic across different links or into different servers. A URL includes a protocol identifier (http, for Web traffic) and a resource name, such as www.microsoft.com.
In simple words, parsing a URL means removing http part of URL, removing all /blah-blah part and just taking the main name of site and checking to what server does this URL map to.
JavaScript is a single threaded langauge then how do websites take care of multiple requests at once? Because these database calls are asynchronous so the thread doesn't have to wait for database call to complete and can still work fine.
This does not holds true in case of busy waiting(Busy waiting, also known as spinning, or busy looping is a process synchronization technique in which a process/task waits and constantly checks for a condition to be satisfied before proceeding with its execution).
We also learned about what public IPs and private IPs are.
Public IP Address:
A public IP address is a unique address assigned to a device on the Internet. It serves as the identifier for that device when communicating across the Internet.
Your router is assigned a public IP address by your Internet Service Provider (ISP). This address is used for communication between your local network and the external Internet.
Private IP Address:
Private IP addresses are used within a local network and are not directly accessible from the Internet. They allow devices within the same local network to communicate with each other.
The range of private IP addresses is defined by specific address blocks reserved for private use. Commonly used private IP address ranges include:
192.168.x.x
172.16.x.x to 172.31.x.x
10.x.x.x
Network Address Translation (NAT):
Since many devices in a local network share the same public IP address, a technique called Network Address Translation (NAT) is used by the router. This allows multiple devices within the local network to use the same public IP address when accessing the Internet.
NAT helps conserve public IP addresses and adds a layer of security by keeping internal IP addresses hidden from the external network.
Access Control:
Devices with private IP addresses within a local network are generally not directly accessible from the Internet. This provides a level of security, as external entities cannot directly connect to devices within the network without specific configurations (such as port forwarding).
1. API (Application Programming Interface)
An API is a set of rules, protocols, and tools that allow different software applications to communicate with each other. It defines how requests and responses should be formatted, which methods to use, and how data can be exchanged between systems.
Purpose: APIs allow the integration of services, enabling applications to interact, request data, or trigger operations in a standardized manner.
Examples: APIs are used in various scenarios, like allowing a mobile app to fetch data from a web server, or letting a website access data from an external service.
2. REST API (Representational State Transfer API)
REST is an architectural style for designing networked applications, particularly web services, that use standard HTTP protocols. A REST API follows the principles of REST and is used to enable communication between clients (e.g., browsers, mobile apps) and servers in a stateless, scalable manner.
Purpose: To facilitate the exchange of data over the web using standard HTTP methods like GET, POST, PUT, DELETE.
Key Features: Statelessness, scalability, cacheability, and use of a uniform interface.
3. REST (Representational State Transfer)
REST itself is not a technology but an architectural style with a set of constraints designed to guide the development of scalable and efficient web services. The core idea is that web resources are represented and can be manipulated using standard HTTP methods.
Core Principles of REST:
Client-Server Architecture: The client and server should be independent; the client requests data, and the server responds with the data.
Statelessness: Each client request to the server must contain all the information the server needs to fulfill the request. No client context is stored on the server between requests.
Cacheability: Responses from the server should be marked as cacheable or non-cacheable to improve efficiency by allowing clients to reuse data.
Uniform Interface: A consistent way to interact with resources, regardless of the client or server implementation. The interface usually involves:
Resource identification (e.g., URIs)
Resource manipulation (via HTTP methods: GET, POST, PUT, DELETE)
Self-descriptive messages (e.g., headers, status codes)
Hypermedia (optional but recommended) to drive the interaction.
Representational in REST:
The term "Representational" refers to the fact that resources (data or services) are represented in a particular format (such as JSON or XML) during communication. Clients can manipulate and exchange these representations while interacting with the server.
4. RESTful API
A RESTful API is an implementation of the REST architectural style. It strictly follows the principles and constraints defined by REST and uses HTTP for communication between clients and servers.
Key Characteristics of RESTful APIs:
Stateless Communication: Each request from the client must contain all the necessary information; no session or user context is stored on the server.
Scalability: RESTful APIs are designed to scale easily across distributed systems.
Use of HTTP Methods:
GET: Retrieve data.
POST: Submit data to the server.
PUT: Update existing data.
DELETE: Remove data from the server.
Data Representation: Resources are represented in formats like JSON, XML, or other data types, and are identified using URIs (Uniform Resource Identifiers).
Stateless Operations: Each operation is independent of any other request, making it easier to scale horizontally (i.e., across multiple servers).
Q. Are REST API and http are interchangeable terms?
While REST API and HTTP are related and often used together, they are not interchangeable terms. Let's clarify the relationship between REST API and HTTP:
HTTP is the protocol that facilitates the communication between clients and servers on the web. REST API is a set of architectural principles that guide the design of web services, and these services often use HTTP as their communication protocol. While RESTful APIs commonly use HTTP, not all HTTP APIs strictly adhere to the principles of REST. The interchangeable aspect often comes from the fact that many web APIs are designed following REST principles and use HTTP as the means of communication. However, it's essential to recognize that REST is an architectural style, and HTTP is a protocol.

We also learned that when we run an express program on a port, we can even access that through our phone, condition being we know the IP of our computer and the phone is connected to the same wifi connection as the computer.

We also got to know that when accessing a website or application over the internet, our request typically travels from our device to the server hosting the website or application. However, simply obtaining the IP address of the server or load balancer might not guarantee access to the desired data. This is because the server often employs mechanisms to verify the legitimacy of incoming requests, such as checking the source of the request.

In essence, a server may use various techniques to determine the authenticity and authorization level of incoming requests. For instance, it might examine the source IP address, inspect cookies, or validate authentication tokens. These measures help ensure that only authorized users gain access to restricted or premium content.

Regarding cookies and authentication keys, if an unauthorized individual gains access to these credentials belonging to an authorized user, they could potentially exploit them to access premium content or perform actions reserved for authenticated users. This underscores the importance of robust security practices, such as employing encryption, strong authentication mechanisms, and regularly updating access controls.

Furthermore, it's worth noting that modern web applications often employ complex architectures, including load balancers, content delivery networks (CDNs), and reverse proxies. These components can distribute incoming traffic across multiple servers and locations, enhancing performance and reliability. As a result, a single IP address might correspond to multiple domains or services, making it more challenging for unauthorized users to directly access sensitive data or premium content without proper authentication and authorization.

In Express.js, req.body is a property used to access the data in the body of a POST, PUT, or PATCH request. However, in order to parse this data and make it available in the req.body object, you need to use middleware. Middleware functions are functions that have access to the request object (req), the response object (res), and the next middleware function in the application’s request-response cycle. Middleware functions can perform actions on the request and response objects, end the request-response cycle, and call the next middleware function in the stack.
Before Express version 4.16.0, the body-parser library was commonly used to parse incoming request bodies. However, since Express 4.16.0, express.json() and express.urlencoded() middleware are built-in middleware functions. This means that you no longer need to explicitly use body-parser for parsing JSON and URL-encoded data.
Here's how each method works:
Using body-parser:
const bodyParser = require('body-parser');
app.use(bodyParser.json());
This line of code tells your Express application to use the body-parser middleware to parse JSON-formatted data.
The body-parser middleware parses the incoming request body in JSON format and makes it available as req.body.
Using express.json():
app.use(express.json());
Starting from Express version 4.16.0, express.json() is a built-in middleware that parses incoming request bodies with JSON payloads.
It essentially does the same thing as body-parser, parsing JSON data and making it available as req.body.
In both cases, the middleware parses the JSON data from the request body and populates the req.body object with the parsed data, making it accessible to your route handlers.
In the context of Express.js, "utils" typically refers to utility functions or modules that provide various helper functionalities for building web applications using the Express framework. These utility functions can include common tasks such as data validation, formatting responses, error handling, authentication, and more.
Express.js itself provides a basic framework for building web applications and APIs, but developers often need to extend its functionality by writing custom middleware or using third-party packages. These utility modules, often referred to as "utils" or "utilities," can help streamline development by providing reusable code for common tasks.
Examples of utilities in Express.js might include:
Validation utilities for validating request data.
Formatting utilities for formatting responses in a consistent manner.
Authentication utilities for handling user authentication and authorization.
Error handling utilities for centralizing error handling logic.
Logging utilities for logging request and response information.
These utilities can be organized into separate modules or packages within an Express.js application to keep the codebase modular and maintainable. Developers may also create their own custom utility functions tailored to the specific requirements of their application.
In the context of Express.js, a "port" refers to a communication endpoint where a server application, such as an Express.js application, listens for incoming network connections. Ports are a fundamental concept in computer networking and are used to enable communication between different processes or services over a network.
Every server application running on a network must listen on a specific port so that clients (other applications or users) can connect to it. When a client wants to communicate with a server, it needs to know the IP address of the server and the port number on which the server is listening.
From a theoretical standpoint, ports are standardized numbers that define specific communication channels. The Internet Assigned Numbers Authority (IANA) maintains a list of well-known port numbers for commonly used services. For example, HTTP typically uses port 80, HTTPS uses port 443, SSH uses port 22, etc. 

HTTPS provides a secure channel between the client and the server to serve this purpose. It uses a network port 443 to transmit the encrypted web traffic over the internet. The standard port for HTTPS is 443. HTTPS provides encryption by using an SSL certificate.

JavaScript is both compiled and interpreted, and the term "Just-In-Time (JIT) compilation" is often associated with its execution. Here's a breakdown:
Interpretation: Initially, JavaScript was primarily interpreted by web browsers. When a browser encounters JavaScript code, it reads the code line by line and executes it immediately.

Compilation: However, modern JavaScript engines use a combination of interpretation and compilation techniques for performance optimization. When the JavaScript code is loaded, it's often parsed into an intermediate representation (IR) or bytecode. This bytecode can then be optimized and compiled into machine code (native code) by the JavaScript engine's compiler.

Just-In-Time (JIT) Compilation: JIT compilation is a technique where parts of the code are compiled into native machine code at runtime, just before they are executed. This allows the JavaScript engine to make optimizations based on runtime information, such as profiling data. Instead of compiling the entire script before execution (ahead-of-time compilation), JIT compilation selectively compiles parts of the code that are frequently executed or are deemed performance-critical.

I had a website in college that pointed to certain IP on the college network, but when I went to another college and put the same IP I got some else data, can you explain more about the concept involved here?
An IP address (Internet Protocol address) is a numerical label assigned to each device connected to a computer network that uses the Internet Protocol for communication. IP addresses serve two main functions: host or network interface identification and location addressing.
When I was in college, you had a website that pointed to a certain IP address on your college network. This means that the domain name of your website was configured to resolve to a specific IP address within your college's local network.
However, when you went to another college and tried to access the same IP address, you received different data. This is because IP addresses are assigned based on networks, and each network can have its own set of IP addresses.

Here's what might have happened:
IP Address Assignment: The same IP address that was assigned to your website at your college might have been assigned to a different service or device at the other college. IP addresses are managed locally by network administrators, and different networks can use the same IP address for different purposes.
Network Routing: Even if the IP address was the same, the data you received could have been different due to network routing. Networks use routers to forward data packets to their destinations. Each college network may have its own routing configuration, directing traffic to different destinations based on the IP address. So, the same IP address could lead to different servers or services depending on the network's routing rules.
Network Segmentation: Colleges often have segmented networks for different purposes, such as academic departments, administrative offices, student dorms, etc. Each segment might have its own set of IP addresses and servers. So, even if the IP address was the same, you might have accessed different data because you were on a different segment of the network.

If you put the same website URL (e.g., www.example.com) into your web browser, the outcome can vary based on several factors, including the DNS (Domain Name System) resolution, network routing, and server configuration. Let's dive deeper into each of these concepts:
DNS Resolution: When you type a website URL into your browser, your computer first needs to resolve that human-readable URL into an IP address. This process is called DNS resolution. Your computer typically queries a DNS server to obtain the IP address associated with the domain name.
If the DNS records for the domain are managed centrally and consistently, you should receive the correct IP address associated with the website, regardless of your physical location or the network you're connected to.
However, if DNS records are managed differently in different network environments (such as at different colleges), you might receive different IP addresses for the same domain. This can happen if each network has its own DNS configuration or if the domain owner uses different DNS settings for different regions or networks.
Network Routing: Once your computer obtains the IP address of the website from DNS resolution, it sends a request to that IP address to retrieve the website's content. Network routing determines how data packets are directed from your device to the destination server and back.
Different networks may have different routing configurations, leading to your request being routed through different paths to reach the destination server.
Additionally, as mentioned earlier, network segmentation can play a role. Even if you access the same website URL from different locations, your requests might traverse different network segments, potentially leading to different servers or services responding to your request.
Server Configuration and Load Balancing: Even if you manage to reach the correct server based on the IP address, the server's configuration and load balancing mechanisms can further influence the data you receive.
Some websites use load balancers to distribute incoming requests across multiple servers. Depending on the load balancer's algorithm and the server's availability, you might be directed to different servers, which could potentially serve slightly different content.
Server-side caching, content delivery networks (CDNs), and personalized content delivery based on your location or browsing history can also affect the data you receive from the server.

Event Loop: In Node.js, JavaScript code runs on a single thread using an event-driven, non-blocking I/O model. The event loop is responsible for handling asynchronous operations efficiently by executing callbacks when asynchronous tasks complete.

The term "parse" in the context of JavaScript and Express typically refers to the process of analyzing a string or data input and converting it into a more structured format that can be easily manipulated or understood by the program. Here's a detailed explanation along with related concepts:
Parsing in JavaScript:

Serialization: The process of converting data structures or objects into a format that can be easily stored or transmitted. JSON serialization involves converting JavaScript objects into JSON strings.
Deserialization: The opposite process of serialization, involving converting a serialized format (such as JSON) back into its original data structure.
Sanitization: The process of cleaning or filtering data to remove potentially malicious or unwanted content.

Setting cookies in the backend when your frontend and backend have different IPs can be achieved through a process called Cross-Origin Resource Sharing (CORS) and the use of HTTP headers. CORS is a mechanism that allows web servers to specify which origins are permitted to access the resources on a server. This mechanism helps prevent unauthorized access to resources across different origins (domains, protocols, or ports).
Here's how you can efficiently set cookies in your backend when your frontend and backend have different IPs:
Enable CORS: Ensure that your backend server is configured to allow cross-origin requests from your frontend IP addresses. This involves setting appropriate CORS headers in your backend server's responses.
Set Cookie with Appropriate Attributes: When setting cookies in your backend, ensure that you include the appropriate attributes such as Secure, HttpOnly, Domain, and Path. These attributes define the scope and security of the cookie.
Secure: Ensures that the cookie is only sent over HTTPS connections, providing encryption to prevent interception of sensitive data.
HttpOnly: Prevents client-side scripts from accessing the cookie, enhancing security by mitigating certain types of attacks such as cross-site scripting (XSS).
Domain: Specifies the domain to which the cookie belongs. This can be set to the domain of your frontend.
Path: Defines the path within the domain for which the cookie is valid. It can restrict the cookie to a specific path on your frontend.
Handle Preflight Requests: For certain types of requests, such as those with custom headers or methods other than GET, POST, or HEAD, the browser may send a preflight request to check if the actual request is safe to send. Your backend should respond appropriately to these preflight requests with the necessary CORS headers.
Testing and Monitoring: After implementing cookie setting in your backend, thoroughly test the functionality across different browsers and environments to ensure compatibility and security. Monitor your backend logs and network traffic to detect any issues or anomalies related to cookie handling.

Cross-Origin Resource Sharing (CORS): A security feature implemented by web browsers that allows web servers to specify which origins have permission to access the resources on a server. CORS helps prevent unauthorized access to resources across different origins.
HTTP Headers: Pieces of information that are exchanged between a client (such as a web browser) and a server as part of the HTTP protocol. Headers convey metadata about the request or response and can include information such as cookies, content type, cache directives, and more.
Secure Cookie: A cookie attribute that ensures the cookie is only sent over secure HTTPS connections, providing encryption to prevent interception of sensitive data.
HttpOnly Cookie: A cookie attribute that prevents client-side scripts from accessing the cookie, enhancing security by mitigating certain types of attacks such as cross-site scripting (XSS).
Domain Attribute: A cookie attribute that specifies the domain to which the cookie belongs. It allows you to restrict the scope of the cookie to a specific domain or subdomain.
Path Attribute: A cookie attribute that defines the path within the domain for which the cookie is valid. It can restrict the cookie to a specific path on the server.

Setting Cookies Across Different Domains: Emphasizes the importance of restricting the ability to set cookies from one domain to another. This restriction is crucial for security purposes, as it helps prevent unauthorized access to sensitive information stored in cookies.

Domain Whitelisting: Your teacher mentions specifying the domains from which cookies can be set. This practice, known as domain whitelisting, involves explicitly allowing requests from trusted domains while denying requests from all others. By whitelisting only a few trusted domains, developers can minimize the risk of unauthorized access and potential security vulnerabilities.

Same-Origin Policy: A security feature implemented by web browsers that restricts interactions between resources from different origins. It prevents scripts running in one origin from accessing resources in another origin unless explicitly permitted by CORS.
Cross-Site Scripting (XSS): A type of security vulnerability where attackers inject malicious scripts into web pages viewed by other users. XSS attacks can be used to steal sensitive information, such as cookies, from legitimate users.
Whitelist: A list of trusted entities or resources that are explicitly allowed or permitted. In the context of web security, domain whitelisting involves specifying trusted domains from which requests are accepted.
Frontend and Backend Separation: Refers to the architectural practice of separating the user interface (frontend) from the application logic and data storage (backend). This separation enhances modularity, scalability, and maintainability of web applications.

The code you provided const port = process.env.PORT || 3000 is a common pattern used in Node.js applications to set up a server's port. Let me break down each part and explain why it's used:

process.env.PORT: This part accesses an environment variable named PORT. Environment variables are variables that are part of the environment in which a process runs. They are external to the code and can be set in the operating system or in a configuration file.
Why use an environment variable for port: By using an environment variable for the port, you allow greater flexibility and configurability. It enables you to run your application on different ports without modifying the source code. For example, in a production environment, you might want to run your application on port 80 or 443 for HTTP or HTTPS respectively, while in a development environment, you might want to run it on a different port like 3000. Using an environment variable allows you to specify the port dynamically based on the environment in which the application is running.
Fallback value: This part ensures that if the PORT environment variable is not set, the server still has a default port to run on.

Query parameters are a way to pass information to a web server by appending key-value pairs to the end of a URL. They are commonly used in HTTP requests to provide additional data to the server, typically for the purpose of filtering, sorting, or modifying the response. Query parameters appear after the question mark (?) in a URL and are separated by ampersands (&) if there are multiple parameters.
For example, consider the following URL:
 
https://example.com/search?q=query&category=books&page=1
In this URL:
https://example.com/search is the base URL.
q=query, category=books, and page=1 are query parameters.

However, passing sensitive information or large amounts of data through query parameters is not recommended for several reasons:
Security: Query parameters are visible in the URL, so sensitive information such as passwords or API keys should not be passed this way to avoid exposing them to potential attackers.
URL Length Limitations: Some browsers and servers have limitations on the length of URLs they can handle. Passing large amounts of data via query parameters can exceed these limits.
Caching and Bookmarking: Query parameters affect caching and bookmarking. If query parameters change frequently, it can lead to caching issues or broken bookmarks.
To avoid passing sensitive information or large data through query parameters, you can use alternative methods such as:
POST Requests: Send data in the body of a POST request instead of appending it to the URL.
Cookies: Store information in cookies, although this also has limitations and security considerations.
Session Management: Store data on the server and associate it with the user's session.
In Express, a popular web framework for Node.js, handling query parameters is straightforward. Express provides the req.query object to access query parameters from incoming HTTP requests. Here's how you can work with query parameters in Express:
const express = require('express');
const app = express();
// Define a route that accepts query parameters
app.get('/search', (req, res) => {
    // Access query parameters using req.query
    const { q, category, page } = req.query;
    
    // Do something with the parameters
    console.log('Search query:', q);
    console.log('Category:', category);
    console.log('Page:', page);
    
    // Send a response
    res.send('Received your query parameters.');
});
// Start the server
app.listen(3000, () => {
    console.log('Server is running on port 3000');
});
In the above example:
The route /search handles GET requests.
Query parameters are accessed using req.query.
The q, category, and page parameters are extracted from req.query.
You can then process these parameters as needed and send an appropriate response.
Express also provides middleware functions for validation, sanitization, and other tasks related to handling query parameters. Additionally, you can use query string parsing libraries like qs or querystring to customize how query parameters are parsed and handled.
npm (Node Package Manager):
npm is the default package manager for the Node.js runtime environment. It allows developers to discover, share, and install JavaScript packages (which are basically libraries or tools) from the npm registry.
npm is primarily used for managing dependencies in Node.js projects, but it's also widely used for managing front-end dependencies and scripts.
package.json:
package.json is a metadata file in JSON format that exists in the root directory of every Node.js package or project.
It includes various configurations such as project metadata (name, version, description, author, license), dependencies (packages required by the project), scripts (commands to run various tasks), and other metadata related to the project.
Developers can manually create and edit this file or use npm commands to generate and manage it.
package-lock.json:
package-lock.json is another JSON file generated by npm, alongside package.json, to lock down the specific versions of dependencies installed in a project.
It ensures that every developer working on the project installs the exact same versions of dependencies, preventing potential inconsistencies due to updates or changes in the npm registry.
This file is automatically generated and updated whenever dependencies are installed or modified using npm.
npx:
npx is a package runner tool that comes bundled with npm version 5.2 and higher.
It allows you to execute npm packages without having to install them globally or locally.
npx searches for executables in the local node_modules/.bin directory first, then looks for them in the system's PATH if not found locally.
It's commonly used for running commands from packages that you don't want to install globally or for executing package-specific scripts without polluting your global or project dependencies.
In summary, npm is a powerful package manager for Node.js projects, package.json is a metadata file that describes the project and its dependencies, package-lock.json locks down specific versions of dependencies, and npx is a tool for executing npm packages without installing them globally or locally. These concepts are fundamental to modern JavaScript development workflows.

Execution Pipeline: V8 executes JavaScript code through multiple stages including parsing, optimizing, and executing. It employs a pipeline model where the code goes through different stages to be transformed and executed efficiently.
JIT Compilation: Just-In-Time compilation is a technique used by V8 to compile JavaScript code into machine code at runtime, which can significantly improve execution speed. V8 uses both a baseline compiler for quick compilation and an optimizing compiler for further performance enhancements.
Garbage Collection: V8 manages memory dynamically and performs automatic garbage collection to reclaim memory that is no longer in use. It employs generational garbage collection algorithms to efficiently manage memory resources.
Isolation: V8 provides isolation mechanisms to execute JavaScript code securely in different environments. For instance, in a web browser, V8 ensures that JavaScript code running in one tab does not interfere with code running in other tabs.

HOMEWORK- 
1) If you feel confident in your ability to code, write a HTTP server from scratch in C++.
2) Create a todo app that lets users store todos on the server
3) Create a http server in rust using actix-web
4) Create a http server in golang using guerilla framework 
5) Create a http server in golang using springboot in java
6) You can also make a sample database with fake generated data and use the backend code using express to generate responses from that data on getting search queries from users.